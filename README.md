# üß¨ BioExpace  
### NASA's Build a Space Biology Knowledge Engine  

---

## üöÄ Introduction  

The project **"Build a Space Biology Knowledge Engine"** aims to obtain information from biological experiments conducted in space over several decades.  
These experiments were recorded as explanatory documents (such as texts).  

Nowadays, we live in an era where **data** is the most important thing in the world (from my point of view).  
We are in the period of **big data** and are beginning to move toward a period of **smart data**.  

With this project, I am applying this concept to **608 scientific documents on space biology**.  
I transform raw data from different sources into **intelligent data** ‚Äî data that allows you to make decisions, plan, or discover things much more quickly and efficiently.  

Certainly, data is very important, but more important than having the data is **knowing what to do with it**.  

The name of the software I created is **BioExpace**, a combination of **Biology** and **Space Exploration**:  
**Bio** (biology, life) + **Ex** (exploration) + **Space** (space).

---

## üß† What does BioExpace do or how does it work?  

In a way, the software performs a flow of ‚Üí **Data Collection ‚Üí Interpretation ‚Üí Synthesis**.

---

### 1Ô∏è‚É£ Data Collection  
It performs **data scraping** on all the links provided as a resource for this project.  
Of course, during scraping there is data treatment, cleaning, etc...

---

### 2Ô∏è‚É£ Interpretation (Qwen ‚Äì Space Biologist Agent)  
After scraping, the data is saved and sent to a **Space Biologist Agent (Qwen from Ollama)**.  

This Space Biologist Agent is responsible for analyzing parts of a document and extracting information in the following format:  
`"points"`, `"cause_effects"`, `"cascade_effects"`, `"observations"`, `"impactful"`.  

I implemented a simple **memory and pipeline logic** so that it can assimilate the last part of the document read with the current one and continue its analysis from there, ensuring it does not get lost or confused, thus allowing it to correctly perform its analysis.

---

### 3Ô∏è‚É£ Synthesis (Llama 3 ‚Äì Data Analyst Agent)  
After that, I have a **Data Analyst Agent (Llama 3 from Ollama)**, whose task is to analyze and understand what was scientifically extracted by the Space Biologist Agent (**Qwen from Ollama**) and generate the **final insight** for the user.  

It also uses the logic of **previous contexts** to perform a complete data analysis.

---

### üß© A few more details...  

- There is an **orchestrator (`orch.py`)** that makes the entire LLM process more organized, monitoring what each one is doing, calling them at the right time, clearly setting each stage, and ‚Äî Pythonically speaking ‚Äî distributing more tasks.  
- There is also a **layer that abstracts all PostgreSQL access** (insertions, connections, etc.).  
- It is the **main execution method** that triggers each defined stage.  
- The extraction process can be done in **real time** or **separately**.  

---

### ü§ñ Why Qwen?  
The reduced model uses **little RAM**, has a **good level of understanding and technical analysis**, and is perfect for **scientific documents**.

### üß© Why Llama 3?  
It generates **more human-like**, **relaxed**, and **understandable** outputs, capable of good exploration and interpretation ‚Äî perfect for taking information and presenting it to the end user as a **practical conclusion**.

---

## üí° What benefits does BioExpace offer?  

It can extract **any data structure** you want from a document and provide you with **intelligent information** based on the given context.  

This summarizes a lot of manual work and saves **human time and energy** from reading and understanding numerous documents.  
This way, you can get **straight to the point**.  

The data is about **Space Biology**, which is essential for understanding how life transforms and adapts in space.  

BioExpace offers a **bridge between knowledge and data** generated by NASA professionals and **modern intelligence** capable of transforming how you perceive data.

---

## üåç What is the intended impact of the project?  

To gather **raw data** and be able to display **valuable information** to the end human user.  

It takes all the sections (for example, *Introduction, Results, Conclusion*) of all documents, analyzes everything, and generates in a **practical and useful way** information that may be valuable to you ‚Äî information that you might spend hours analyzing to find what you're looking for.

---

## üß∞ Which tools, programming languages, hardware, or software did you use to develop your project?  

**Languages:**  
Python, HTML, CSS, and JavaScript  

**Frameworks:**  
- Flask (good for microservices)  
- Ollama (for integrating LLMs on my local machine)  
- TikToken (for token control by chunk)  

**Database:**  
PostgreSQL (used to store data collection, agent pipelines, and the structure of the final result)  

**Final Data Format:**  
JSON (JSONB in PostgreSQL)  

**Hardware:**  
Local server with only CPU, 16GB of RAM, Ubuntu operating system, no cloud dependency.

---

## üß† How is your project creative?  

It uses **text comprehension models (NLP)** to analyze thousands of tokens in documents, assimilate everything, organize everything, and generate **valuable information**.  

It allows **quick access to information** and the possible generation of **new biological hypotheses** thanks to what the Agents provide to us humans.  

Furthermore, the idea of **collaborative cognitive agents** (one reads, another interprets) and the fusion of **space biology and intelligent data** (thanks to AI) embody the notion of **augmented science** ‚Äî the way data is transformed into **intelligent information** for this branch of science.  

There are **two agents** working on multiple scientific documents, reviewing and generating information.

---

## üë• What factors did your team consider?  

The fact is that today, we humans are always needing more **convenience**, more **objectivity**, and more **speed**.  

Tools like this ‚Äî which save **85% of your work time** ‚Äî make you **more productive**.  

And of course, the better the LLM model used, the smarter and better your final result will be.

---

